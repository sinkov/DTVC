{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a60729a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import io\n",
    "from selenium import webdriver\n",
    "from selenium.common import exceptions\n",
    "import time\n",
    "import pandas as pd\n",
    "def scrape(url,n):\n",
    "    \"\"\"\n",
    "    Extracts the comments from the Youtube video given by the URL.\n",
    "    Args:\n",
    "        url (str): The URL to the Youtube video\n",
    "    Raises:\n",
    "        selenium.common.exceptions.NoSuchElementException:\n",
    "        When certain elements to look for cannot be found\n",
    "    \"\"\"\n",
    "    # Note: Download and replace argument with path to the driver executable.\n",
    "    # Simply download the executable and move it into the webdrivers folder.\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    # Navigates to the URL, maximizes the current window, and\n",
    "    # then suspends execution for (at least) 5 seconds (this\n",
    "    # gives time for the page to load).\n",
    "    driver.get(url)\n",
    "    driver.maximize_window()\n",
    "    time.sleep(5)\n",
    "\n",
    "    try:\n",
    "        # Extract the elements storing the video title and\n",
    "        # comment section.\n",
    "        title = driver.find_element_by_xpath('//*[@id=\"container\"]/h1/yt-formatted-string').text\n",
    "        comment_section = driver.find_element_by_xpath('//*[@id=\"comments\"]')\n",
    "    except exceptions.NoSuchElementException:\n",
    "        # Note: Youtube may have changed their HTML layouts for\n",
    "        # videos, so raise an error for sanity sake in case the\n",
    "        # elements provided cannot be found anymore.\n",
    "        error = \"Error: Double check selector OR \"\n",
    "        error += \"element may not yet be on the screen at the time of the find operation\"\n",
    "        print(error)\n",
    "\n",
    "    # Scroll into view the comment section, then allow some time\n",
    "    # for everything to be loaded as necessary.\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", comment_section)\n",
    "    time.sleep(7)\n",
    "\n",
    "    # Scroll all the way down to the bottom in order to get all the\n",
    "    # elements loaded (since Youtube dynamically loads them).\n",
    "    last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        # Scroll down 'til \"next load\".\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "\n",
    "        # Wait to load everything thus far.\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height.\n",
    "        new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # One last scroll just in case.\n",
    "    driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "\n",
    "    try:\n",
    "        # Extract the elements storing the usernames and comments.\n",
    "        #username_elems = driver.find_elements_by_xpath('//*[@id=\"author-text\"]')\n",
    "        comment_elems = driver.find_elements_by_xpath('//*[@id=\"content-text\"]')\n",
    "    except exceptions.NoSuchElementException:\n",
    "        error = \"Error: Double check selector OR \"\n",
    "        error += \"element may not yet be on the screen at the time of the find operation\"\n",
    "        print(error)\n",
    "\n",
    "    print(\"> VIDEO TITLE: \" + title + \"\\n\")\n",
    "    with io.open(str(n)+'.csv', 'w', newline='', encoding=\"utf-16\") as file:\n",
    "        writer = csv.writer(file, delimiter =\",\", quoting=csv.QUOTE_ALL)\n",
    "        writer.writerow([\"Comment\"])\n",
    "        for comment in comment_elems:\n",
    "            writer.writerow([comment.text])\n",
    "    driver.close()\n",
    "    \n",
    "#if __name__ == \"__main__\":\n",
    " #   scrape(sys.argv[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f334f6d8",
   "metadata": {},
   "source": [
    "## Youtube links of commercials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd672dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_list=['https://www.youtube.com/watch?v=0lr4KoiKDWo&t=2s',\n",
    "'https://www.youtube.com/watch?v=ei257XFDMKY',\n",
    "'https://www.youtube.com/watch?v=Kp1P4S-WgvU',\n",
    "'https://www.youtube.com/watch?v=tSAYtwTqppA',\n",
    "'https://www.youtube.com/watch?v=8yGN55SkXGY',\n",
    "'https://www.youtube.com/watch?v=vdpu1wPh0Kw',\n",
    "'https://www.youtube.com/watch?v=KwcodBLXK70',\n",
    "'https://www.youtube.com/watch?v=gGZx0RrL-ow',\n",
    "'https://www.youtube.com/watch?v=HmBwSAS39r8',\n",
    "'https://www.youtube.com/watch?v=C7XUGgztD_U',\n",
    "'https://www.youtube.com/watch?v=FCmG5tE7zEw',\n",
    "'https://www.youtube.com/watch?v=TLcG2eYN3eI&t=1s',\n",
    "'https://www.youtube.com/watch?v=HpONp44F8E0',\n",
    "'https://www.youtube.com/watch?v=8YiEmekf_34&t=3s',\n",
    "'https://www.youtube.com/watch?v=WNarpiGz3Kk&t=2s',\n",
    "'https://www.youtube.com/watch?v=UFBPsEOuKqw',\n",
    "'https://www.youtube.com/watch?v=xMZaObIQps8',\n",
    "'https://www.youtube.com/watch?v=nvTWLKBsNjE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d2f81f",
   "metadata": {},
   "source": [
    "## Scrape those urls using pre-defined 'scrape' function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39a1305e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> VIDEO TITLE: Nightmare on Night Sight: #TeamPixel Goes Ghost Hunting With Pixel 6\n",
      "\n",
      "> VIDEO TITLE: Life of Photos on Pixel 6: For All You Are\n",
      "\n",
      "> VIDEO TITLE: Pixel 6 and Pixel 6 Pro Camera - Pixel 6 Launch\n",
      "\n",
      "> VIDEO TITLE: Speech Recognition Powered by Google Tensor - Pixel 6 Launch\n",
      "\n",
      "> VIDEO TITLE: Live Translate. Interpreter Mode Demo with Marie Kondo - Pixel 6 Launch\n",
      "\n",
      "> VIDEO TITLE: In-Depth Magic Eraser Demo - Pixel 6 Launch\n",
      "\n",
      "> VIDEO TITLE: Google Tensor - Pixel 6 Launch\n",
      "\n",
      "> VIDEO TITLE: Real Tone in Pixel Camera and Google Photos - Pixel 6 Launch\n",
      "\n",
      "> VIDEO TITLE: Android 12 and Material You - Pixel 6 Launch\n",
      "\n",
      "> VIDEO TITLE: First Pixel 6 Unboxing - Pixel 6 Launch\n",
      "\n",
      "> VIDEO TITLE: Real Tone and Picture Progress - Pixel 6 Launch\n",
      "\n",
      "> VIDEO TITLE: Design Tour - Pixel 6 Launch\n",
      "\n",
      "> VIDEO TITLE: Reimagined Inside and Out â€“ Pixel 6 and Pixel 6 Pro in 6 New Colors\n",
      "\n",
      "> VIDEO TITLE: Meet Pixel 6 and Pixel 6 Pro\n",
      "\n",
      "> VIDEO TITLE: Google Presents: Pixel Fall Launch\n",
      "\n",
      "> VIDEO TITLE: Pixel Buds A-Series Review: Thoughts from #TeamPixel\n",
      "\n",
      "> VIDEO TITLE: Google Pixel 6 - For All You Are\n",
      "\n",
      "> VIDEO TITLE: How to Use One-Handed Mode on Google Pixel\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "youtube_comments=[]\n",
    "for url in scrape_list:\n",
    "    i+=1\n",
    "    data=scrape(url,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3d51ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1.csv', newline='', encoding=\"utf16\") as MyFile: \n",
    "    text = pd.read_csv(MyFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc2fbd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('2.csv', newline='', encoding=\"utf16\") as MyFile: \n",
    "    text2 = pd.read_csv(MyFile)\n",
    "    text=text.append(text2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7876a749",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('3.csv', newline='', encoding=\"utf16\") as MyFile: \n",
    "    text3 = pd.read_csv(MyFile)\n",
    "    text=text.append(text3, ignore_index=True)\n",
    "with open('4.csv', newline='', encoding=\"utf16\") as MyFile: \n",
    "    text4 = pd.read_csv(MyFile)\n",
    "    text=text.append(text4, ignore_index=True)\n",
    "with open('5.csv', newline='', encoding=\"utf16\") as MyFile: \n",
    "    text5 = pd.read_csv(MyFile)\n",
    "    text=text.append(text5, ignore_index=True)\n",
    "with open('6.csv', newline='', encoding=\"utf16\") as MyFile: \n",
    "    text6 = pd.read_csv(MyFile)\n",
    "    text=text.append(text6, ignore_index=True)\n",
    "with open('7.csv', newline='', encoding=\"utf16\") as MyFile: \n",
    "    text7 = pd.read_csv(MyFile)\n",
    "    text=text.append(text7, ignore_index=True)\n",
    "with open('8.csv', newline='', encoding=\"utf16\") as MyFile: \n",
    "    text8 = pd.read_csv(MyFile)\n",
    "    text=text.append(text8, ignore_index=True)\n",
    "with open('9.csv', newline='', encoding=\"utf16\") as MyFile: \n",
    "    text9 = pd.read_csv(MyFile)\n",
    "    text=text.append(text9, ignore_index=True)\n",
    "with open('10.csv', newline='', encoding=\"utf16\") as MyFile: \n",
    "    text10 = pd.read_csv(MyFile)\n",
    "    text=text.append(text10, ignore_index=True)\n",
    "with open('11.csv', newline='', encoding=\"utf16\") as MyFile: \n",
    "    text11 = pd.read_csv(MyFile)\n",
    "    text=text.append(text11, ignore_index=True)\n",
    "with open('12.csv', newline='', encoding=\"utf16\") as MyFile: \n",
    "    text12 = pd.read_csv(MyFile)\n",
    "    text=text.append(text12, ignore_index=True)\n",
    "with open('13.csv', newline='', encoding=\"utf16\") as MyFile: \n",
    "    text13 = pd.read_csv(MyFile)\n",
    "    text=text.append(text13, ignore_index=True)\n",
    "with open('14.csv', newline='', encoding=\"utf16\") as MyFile: \n",
    "    text14 = pd.read_csv(MyFile)\n",
    "    text=text.append(text14, ignore_index=True)\n",
    "with open('15.csv', newline='', encoding=\"utf16\") as MyFile: \n",
    "    text15 = pd.read_csv(MyFile)\n",
    "    text=text.append(text15, ignore_index=True)\n",
    "with open('16.csv', newline='', encoding=\"utf16\") as MyFile: \n",
    "    text16 = pd.read_csv(MyFile)\n",
    "    text=text.append(text16, ignore_index=True)\n",
    "with open('17.csv', newline='', encoding=\"utf16\") as MyFile: \n",
    "    text17 = pd.read_csv(MyFile)\n",
    "    text=text.append(text17, ignore_index=True)\n",
    "with open('18.csv', newline='', encoding=\"utf16\") as MyFile: \n",
    "    text18 = pd.read_csv(MyFile)\n",
    "    text=text.append(text18, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bb022edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.to_pickle('./youtube18.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303c6bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
